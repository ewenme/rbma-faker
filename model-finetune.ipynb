{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Train a GPT-2 Text-Generating Model w/ GPU",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ewenme/rbma-faker/blob/master/model-finetune.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7LoMj4GA4n_",
        "colab_type": "text"
      },
      "source": [
        "#  Train a GPT-2 Text-Generating Model w/ GPU\n",
        "\n",
        "For more about `gpt-2-simple`, you can visit [this GitHub repository](https://github.com/minimaxir/gpt-2-simple).\n",
        "\n",
        "\n",
        "To get started:\n",
        "\n",
        "1. Copy this notebook to your Google Drive to keep it and save your changes. (File -> Save a Copy in Drive)\n",
        "2. Make sure you're running the notebook in Google Chrome.\n",
        "3. Run the cells below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBkpRgBCBS2_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 203
        },
        "outputId": "8e257816-ba0e-401d-f68c-687f6fb61499"
      },
      "source": [
        "!pip install -q gpt-2-simple\n",
        "import gpt_2_simple as gpt2\n",
        "from datetime import datetime\n",
        "from google.colab import files"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:\n",
            "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
            "For more information, please see:\n",
            "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
            "  * https://github.com/tensorflow/addons\n",
            "  * https://github.com/tensorflow/io (for I/O related ops)\n",
            "If you depend on functionality not listed there, please file an issue.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0wXB05bPDYxS",
        "colab_type": "text"
      },
      "source": [
        "## Downloading GPT-2\n",
        "\n",
        "If you're retraining a model on new text, you need to download the GPT-2 model first. \n",
        "\n",
        "There are three released sizes of GPT-2:\n",
        "\n",
        "* `124M` (default): the \"small\" model, 500MB on disk.\n",
        "* `355M`: the \"medium\" model, 1.5GB on disk.\n",
        "* `774M`: the \"large\" model, cannot currently be finetuned with Colaboratory but can be used to generate text from the pretrained model (see later in Notebook)\n",
        "\n",
        "Larger models have more knowledge, but take longer to finetune and longer to generate text. You can specify which base model to use by changing `model_name` in the cells below.\n",
        "\n",
        "The next cell downloads it from Google Cloud Storage and saves it in the Colaboratory VM at `/models/<model_name>`.\n",
        "\n",
        "This model isn't permanently saved in the Colaboratory VM; you'll have to redownload it if you want to retrain it at a later time."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P8wSlgXoDPCR",
        "colab_type": "code",
        "outputId": "a55ee22f-04d3-41d1-947d-7e4386c81c0f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "gpt2.download_gpt2(model_name=\"124M\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 275Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 98.5Mit/s]                                                   \n",
            "Fetching hparams.json: 1.05Mit [00:00, 638Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 498Mit [00:02, 172Mit/s]                                   \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 606Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 1.05Mit [00:00, 154Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 143Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N8KXuKWzQSsN",
        "colab_type": "text"
      },
      "source": [
        "## Mounting Google Drive\n",
        "\n",
        "The best way to get input text to-be-trained into the Colaboratory VM, and to get the trained model *out* of Colaboratory, is to route it through Google Drive *first*.\n",
        "\n",
        "Running this cell (which will only work in Colaboratory) will mount your personal Google Drive in the VM, which later cells can use to get data in/out. (it will ask for an auth code; that auth is not saved anywhere)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "puq4iC6vUAHc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "f9f7d3a2-646d-4bd0-a88c-8f46ac1c41b0"
      },
      "source": [
        "gpt2.mount_gdrive()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BT__brhBCvJu",
        "colab_type": "text"
      },
      "source": [
        "## Uploading a Text File to be Trained to Colaboratory\n",
        "\n",
        "In the Colaboratory Notebook sidebar on the left of the screen, select *Files*. From there you can upload files:\n",
        "\n",
        "![alt text](https://i.imgur.com/TGcZT4h.png)\n",
        "\n",
        "Upload **any smaller text file**  (<10 MB) and update the file name in the cell below, then run the cell."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OFnPCLADfll",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "file_name = \"rbma-lecture-transcripts.txt\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeeSKtNWUedE",
        "colab_type": "text"
      },
      "source": [
        "If your text file is larger than 10MB, it is recommended to upload that file to Google Drive first, then copy that file from Google Drive to the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Z6okFD8VKtS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_file_from_gdrive(file_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdpZQXknFNY3",
        "colab_type": "text"
      },
      "source": [
        "## Finetune GPT-2\n",
        "\n",
        "The next cell will start the actual finetuning of GPT-2. It creates a persistent TensorFlow session which stores the training config, then runs the training for the specified number of `steps`. (to have the finetuning run indefinitely, set `steps = -1`)\n",
        "\n",
        "The model checkpoints will be saved in `/checkpoint/run1` by default. The checkpoints are saved every 500 steps (can be changed) and when the cell is stopped.\n",
        "\n",
        "The training might time out after 4ish hours; make sure you end training and save the results so you don't lose them!\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files.\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.finetune`:\n",
        "\n",
        "\n",
        "*  **`restore_from`**: Set to `fresh` to start training from the base GPT-2, or set to `latest` to restart training from an existing checkpoint.\n",
        "* **`sample_every`**: Number of steps to print example output\n",
        "* **`print_every`**: Number of steps to print training progress.\n",
        "* **`learning_rate`**:  Learning rate for the training. (default `1e-4`, can lower to `1e-5` if you have <1MB input data)\n",
        "*  **`run_name`**: subfolder within `checkpoint` to save the model. This is useful if you want to work with multiple models (will also need to specify  `run_name` when loading the model)\n",
        "* **`overwrite`**: Set to `True` if you want to continue finetuning an existing model (w/ `restore_from='latest'`) without creating duplicate copies. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aeXshJM-Cuaf",
        "colab_type": "code",
        "outputId": "9af08b7f-a743-45b8-ea73-91bd91c0ec64",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.finetune(sess,\n",
        "              dataset=file_name,\n",
        "              model_name='124M',\n",
        "              steps=1000,\n",
        "              restore_from='fresh',\n",
        "              run_name='run1',\n",
        "              print_every=10,\n",
        "              sample_every=200,\n",
        "              save_every=500\n",
        "              )"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/gpt_2_simple/src/sample.py:17: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Loading checkpoint models/124M/model.ckpt\n",
            "INFO:tensorflow:Restoring parameters from models/124M/model.ckpt\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r  0%|          | 0/1 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading dataset...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\r100%|██████████| 1/1 [00:38<00:00, 38.94s/it]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "dataset has 7568903 tokens\n",
            "Training...\n",
            "[10 | 52.08] loss=3.06 avg=3.06\n",
            "[20 | 98.12] loss=2.85 avg=2.96\n",
            "[30 | 144.13] loss=3.00 avg=2.97\n",
            "[40 | 190.06] loss=2.91 avg=2.96\n",
            "[50 | 236.06] loss=2.86 avg=2.94\n",
            "[60 | 282.01] loss=2.81 avg=2.91\n",
            "[70 | 328.02] loss=2.82 avg=2.90\n",
            "[80 | 373.98] loss=2.69 avg=2.87\n",
            "[90 | 419.95] loss=2.79 avg=2.86\n",
            "[100 | 466.04] loss=2.88 avg=2.87\n",
            "[110 | 512.20] loss=2.84 avg=2.86\n",
            "[120 | 558.32] loss=2.80 avg=2.86\n",
            "[130 | 604.45] loss=2.81 avg=2.85\n",
            "[140 | 650.63] loss=2.70 avg=2.84\n",
            "[150 | 696.91] loss=2.90 avg=2.85\n",
            "[160 | 743.08] loss=2.91 avg=2.85\n",
            "[170 | 789.30] loss=2.72 avg=2.84\n",
            "[180 | 835.48] loss=2.83 avg=2.84\n",
            "[190 | 881.65] loss=2.72 avg=2.83\n",
            "[200 | 927.85] loss=2.75 avg=2.83\n",
            "======== SAMPLE 1 ========\n",
            " some way, I think it's more of that the kind of people we need are kind of, yeah. We’ll see how many people we get.\n",
            "Todd L. Burns \n",
            "Yeah, we’ll, yeah. And we could do another video series that was actually not really aimed at us and we wanted somebody who would want to do that. We would like to find out a little bit about what we’d been working on here. We know it’s pretty much what we know, but we’re trying to figure out a little bit of the story and so then we could move forward.\n",
            "Todd L. Burns \n",
            "How did you meet and then go to Germany?\n",
            "Torsten Schmidt\n",
            "It’s a cool place. So, I’d just go see a music store called The Sörenkraft or something, so maybe if I come in here, I can make it, or if I don’t come in here, I can get the records by myself. I guess the Sörenkraft and whatnot and stuff, because I’m probably from Germany, so there’s a lot of different influences. It’s just one thing to be in Berlin, a lot of different groups, different music places and things.\n",
            "Todd L. Burns \n",
            "So, we’re doing this album for Berlin, yeah.\n",
            "Torsten Schmidt\n",
            "For me, like, I don’t know how to play it, because we have a lot of different artists, people, just different music, different people to play that record.\n",
            "Todd L. Burns \n",
            "How did you guys play the record?\n",
            "Torsten Schmidt\n",
            "And we didn’t have our own music. We didn’t mix anything, or we would play something, like, some track from one of my favorite records, like, “Por,” something I’m a fan of. It’s different to what you have to do with the record. It’s just different to do it.\n",
            "Todd L. Burns \n",
            "What happened in there?\n",
            "Torsten Schmidt\n",
            "We were playing something called the Baseweck records at a local festival. The Baseweck recordings, you know? And it would have an idea of what was going on and if you wanted it. So, we would listen to what we liked on the Baseweck. We would play a song and we would tell you what we liked from the record. And we would try and go and just try and tell you what we did that way. In Berlin, like I’m telling you, what you have to have to do is like the Baseweck.\n",
            "Todd L. Burns \n",
            "Were there any songs you were thinking off it for?\n",
            "Torsten Schmidt\n",
            "[music] Sometimes we don’t want to have to use, but once I play this record and start playing it again and make sure this isn’t just that one song it’s so simple and so catchy and it gets me more excited because we are using songs and just just making sure. So, that’s where it is kind of. But what did I notice?\n",
            "Todd L. Burns \n",
            "What happens later, when you play something and think “Hey, this is not going to be like this.” [laughs] And you kind of remember that in the song. That’s not a good thing, it’s not really a good thing. We play that because we don’t want to have to play a song, so it’s kind of a nice thing.\n",
            "Todd L. Burns \n",
            "This is a different kind of song.\n",
            "Torsten Schmidt\n",
            "So, with this record, we put it in. We played it. In the song there is this thing called “Por,” it was like, “Por,” right next to something that we like better, that’s the way that we want to see how many songs we play. So if we can have a little bit here and there, but that doesn’t change much.\n",
            "Todd L. Burns \n",
            "That feels like a different kind of song.\n",
            "Torsten Schmidt\n",
            "So, the music we were doing in it, the track is only half that and just like the melodies in it, a little bit more in rhythm, we can play melodies. The tracks are in real sound, some rhythm, some simple beats and melodies. So, when we put them in the song, they're actually written in a real rhythm and a nice little bit of, like a little bit of... “Por,” is there one thing that can change a song and change it in an instant.\n",
            "Todd L. Burns \n",
            "When you played this, how did you decide to put the music\n",
            "\n",
            "[210 | 992.01] loss=2.75 avg=2.83\n",
            "[220 | 1038.19] loss=2.61 avg=2.81\n",
            "[230 | 1084.40] loss=2.90 avg=2.82\n",
            "[240 | 1130.63] loss=2.74 avg=2.82\n",
            "[250 | 1176.88] loss=2.82 avg=2.82\n",
            "[260 | 1223.10] loss=2.75 avg=2.81\n",
            "[270 | 1269.24] loss=2.86 avg=2.81\n",
            "[280 | 1315.41] loss=2.68 avg=2.81\n",
            "[290 | 1361.57] loss=2.79 avg=2.81\n",
            "[300 | 1407.74] loss=2.90 avg=2.81\n",
            "[310 | 1453.85] loss=2.90 avg=2.82\n",
            "[320 | 1500.01] loss=2.67 avg=2.81\n",
            "[330 | 1546.20] loss=2.82 avg=2.81\n",
            "[340 | 1592.35] loss=2.70 avg=2.81\n",
            "[350 | 1638.52] loss=2.74 avg=2.80\n",
            "[360 | 1684.63] loss=2.83 avg=2.81\n",
            "[370 | 1730.61] loss=2.68 avg=2.80\n",
            "[380 | 1776.53] loss=2.88 avg=2.80\n",
            "[390 | 1822.49] loss=2.83 avg=2.80\n",
            "[400 | 1868.41] loss=2.80 avg=2.80\n",
            "======== SAMPLE 1 ========\n",
            "Yeah, it’s cool, but there will be a few of us who will look at it as something that we can use. And there will be a few of us who don’t really care, but you have to ask yourself if it’s actually cool. And that’s how to do it. I have one friend who does a lot of sound design, and he’s a musician, and he’s a bit of a weirdo in that regard, not that he’s interested in what other people are doing but that he’s kind of interested in, I think, what he says in the press and whatever, which is interesting at the moment, because, that’s what I want to play. But I’ve got this sound that I want to have for my records and I want to do it as well. \n",
            "And this is how I got there, because when I think back, ’85 I remember going back to the first time that I opened my first label after just starting in New York, that it was just going to be this kind of record. Because I was the very first guy, and I think I was the biggest artist in the world on that first record. But, I still thought I’d go that way, that it was a very strange thing, and I didn’t really understand what I was doing. I just put my name on in this way that I thought, ‘Well, the only way I could get people involved and get this whole thing going, that was to a certain extent, it was just, it had this sort of mystique to it, in the sense that it was all music. And I think it became a very popular thing to do it, and it’s just a big, heavy, noisy thing that’s kind of about to change the world. And we have a good, long standing relationship with the world that we’re from now, the Internet. So when I get back to the moment when I first bought my first house, I really started looking in that direction, and the way I got into music, I start having a sense of humor, in that, and a certain spirit about it that I’ve only really touched on a little bit, and in the last 12 or 15 years, of course, the Internet has changed the world. But, I think that that’s the thing that really gives me an advantage. And a lot of those young guys that are in the music business now, they’m, like me, they’re like, “Where is that in New York?” They know better than to speak for themselves, but I think, yeah, like I say in the press, I have to keep going to the same level to make music. Like I say I don’t have to speak in a way about it, I’re not going to have to... I don’t think I have to. I’ll be there. I don’t have to. And I just need to get around to making music, and I’ve got my own little studio, and I’ve got a lot of stuff to do. And it is going to take me a half hour to make sure I’re getting to what I’ve got. So, I’ll do it over the next couple of weeks. You know, it has all these elements to it, but the question remains if it’s gonna change that or if it’s gonna stay the same, or if it’s gonna get another level like what the last record we did was like, “OK, it’s really gonna come back.” It’s a pretty serious question, that question is the answer.\n",
            "Audience member\n",
            "I was, like I asked people, you know, there was an old school hip-hop label called the Young Future Records.\n",
            "(music: Young Future Records – “I’m A Rock & Roll Rapper” / applause)\n",
            "And, you know, you have some really great people that are doing good stuff, but that’s the kind of thing that’s gonna help me find some new music. And I can talk about the hip-hop thing now, and the way that they started to do these big releases, that became very much about, you know? They could really put out some great singles, and people from the past called, “You know what? You put out a couple of really good records, but they’re kind of getting tired of you guys coming out and you’re like, “OK, we wanna play more of those, it’s got to be cool. You just want to play more of these,” and they’ve just been successful... [\n",
            "\n",
            "[410 | 1931.26] loss=2.92 avg=2.81\n",
            "[420 | 1977.17] loss=2.82 avg=2.81\n",
            "[430 | 2023.29] loss=2.95 avg=2.81\n",
            "[440 | 2069.38] loss=2.70 avg=2.81\n",
            "[450 | 2115.55] loss=2.89 avg=2.81\n",
            "[460 | 2161.65] loss=2.70 avg=2.81\n",
            "[470 | 2207.75] loss=2.70 avg=2.81\n",
            "[480 | 2253.86] loss=2.69 avg=2.80\n",
            "[490 | 2299.90] loss=2.70 avg=2.80\n",
            "[500 | 2346.00] loss=2.76 avg=2.80\n",
            "Saving checkpoint/run1/model-500\n",
            "[510 | 2395.07] loss=2.65 avg=2.79\n",
            "[520 | 2441.24] loss=2.75 avg=2.79\n",
            "[530 | 2487.42] loss=2.74 avg=2.79\n",
            "[540 | 2533.62] loss=2.81 avg=2.79\n",
            "[550 | 2579.75] loss=2.71 avg=2.79\n",
            "[560 | 2625.97] loss=2.61 avg=2.79\n",
            "[570 | 2672.14] loss=2.71 avg=2.78\n",
            "[580 | 2718.28] loss=2.68 avg=2.78\n",
            "[590 | 2764.44] loss=2.72 avg=2.78\n",
            "[600 | 2810.56] loss=2.66 avg=2.78\n",
            "======== SAMPLE 1 ========\n",
            " the album was something which I didn’t get much opportunity to do because you just made your way through them to the people and I think a lot of people got confused. Obviously there’s a lot of musicians that you can’t do that well. There’s a lot of musicians that you can do that well because there’s too much talent around the studio in the beginning to just have the right mix. I think, especially in the States, the mix is going to be, if there’s no talent around, it won’t work.\n",
            "A&E\n",
            "I don’t know how I know that.\n",
            "Morton Subotnick\n",
            "Well, there’s a lot of talent around you. We definitely have a lot of talent around us but the other thing is, everybody who’s been around me, everybody you see in New York, you just see people you know, you know, that’s all you do. It’s a great environment. And the people that I know here in New York, it’s a great environment. I’m in the studio here in Chicago, I’m the first one in here. I’m just living my life around me. I’m just moving around.\n",
            "A&E\n",
            "No, I’m doing my own stuff. I’m not doing stuff just because the studio is a great place. Not just a great place, as we all know, it’s not just one or two or anything that it’s all about. It’s about putting it all together.\n",
            "Morton Subotnick\n",
            "That’s always a great topic for this interview, so we’ll move to a different angle and hopefully you can understand why this topic so many people are going to questions about this week.\n",
            "Jeff Mao \n",
            "One thing to note is that I would just like to keep it fun, to remember that in a lot of the bands, there’s a lot of people that are really good in terms of creativity. It’s not an easy one.\n",
            "There’s always people coming up and talking about how you can do something for the studio, the idea…\n",
            "A&E\n",
            "Yeah, I was doing [the album] with a friend of mine from Texas.\n",
            "Jeff Mao \n",
            "Why does this album seem like a really big deal to you when you know what you are doing?\n",
            "A&E\n",
            "I really want to work with artists who I like and I want to do things with them, and in the end it’s all about making music, not just about one thing.\n",
            "Jeff Mao \n",
            "That’s a common thread, right? [inaudible]\n",
            "Morton Subotnick \n",
            "Yeah, that’s what I’m trying to say, is everybody’s not going to have a perfect studio or a perfect studio, all the time.\n",
            "Jeff Mao \n",
            "This was your first day at the studio.\n",
            "A&E\n",
            "Yeah, it was my first day with a new studio. I was coming out of Chicago a couple of weeks ago, and the first day I took the studio I was in, was just... It was my first day. It was just the experience, the new studio, and that’s it.\n",
            "I don’t know if it was a great studio or not, as it was a great studio, but when I got to New York it was like it’s my whole life. I’m doing a lot of music here, I’m playing, I’m going to the studio, I’m writing records, I’m playing, stuff.\n",
            "Now, with being a full-time artist now you just have a big studio. I was getting very much into that, where I put everything, and then there was a lot of the other stuff I was producing, and I was like, “Hey, what you’re supposed to bring and have.” I was getting more into that because I was always producing, I’m always playing, there was a lot of that stuff that was coming out, and I’m coming up with new stuff. I’m trying to make music and I’m always learning, and now that I am an artist, I’m really enjoying it all.\n",
            "It’s always just about making a change. The idea of playing in this environment, that’s always a great environment for me. It’s just a great environment. And also, because I’m a producer, it’s really easy and it’s a super simple thing; you know, it’s not... It’s not even complicated, it’s just\n",
            "\n",
            "[610 | 2873.47] loss=2.86 avg=2.78\n",
            "[620 | 2919.68] loss=2.71 avg=2.78\n",
            "[630 | 2965.80] loss=2.71 avg=2.78\n",
            "[640 | 3011.98] loss=2.80 avg=2.78\n",
            "[650 | 3058.07] loss=2.55 avg=2.77\n",
            "[660 | 3104.26] loss=2.75 avg=2.77\n",
            "[670 | 3150.45] loss=2.67 avg=2.77\n",
            "[680 | 3196.59] loss=2.70 avg=2.77\n",
            "[690 | 3242.75] loss=2.56 avg=2.76\n",
            "[700 | 3288.91] loss=2.59 avg=2.76\n",
            "[710 | 3335.09] loss=2.59 avg=2.76\n",
            "[720 | 3381.23] loss=2.67 avg=2.76\n",
            "[730 | 3427.39] loss=2.78 avg=2.76\n",
            "[740 | 3473.57] loss=2.92 avg=2.76\n",
            "[750 | 3519.72] loss=2.78 avg=2.76\n",
            "[760 | 3565.80] loss=2.74 avg=2.76\n",
            "[770 | 3611.77] loss=2.91 avg=2.76\n",
            "[780 | 3657.93] loss=2.62 avg=2.76\n",
            "[790 | 3704.12] loss=2.67 avg=2.76\n",
            "[800 | 3750.27] loss=2.75 avg=2.76\n",
            "======== SAMPLE 1 ========\n",
            " be a lot of us doing a lot of shit. You know? It was the first time, and most of the cats I know didn’t have it. Some of them had it. Like, when the first couple of the bands were, I think that was our first taste of electronic music, I think it was. Then you had the Beatles. \n",
            "You don’t necessarily have to have this, but you might be aware of the song \"I Can Drive You Crazy\" or other such things. And if that’s where you’re at, it’s probably your own preference when you’re into it. It’s always something you might have to give back to someone or something.\n",
            "Chal Ravens\n",
            "You’re right on point – it has to do for the producers, for the record companies, that it’s always about the producer. They have to be in control, it all comes into play. If you like, you know, we’re the most confident producers in the world. No one knows that you have to be in control but if you’re not, then it’s fine. \n",
            "In the beginning, I think it was a lot of us really, if we could find it, we would be so confident, because when bands started to do things like record sales were dropping and stuff like that, we kind of became a bit more confident. “Man, you have to be fearless because you’ve got to do something.” I mean just because somebody said something and you said something. They don’t have to be the aggressor and they have the confidence to take the risk, and I didn’t like that because that was the way we were doing it so well. I said to someone, as we’ve been here and we have the confidence to do whatever we want to do and we don’t really have to go out and do something too far in your face. We just want to be cool. “Damn, I can do something too,”” and then, “Man I’ll be in control, and then, you know,” and we went with it.\n",
            "Chal Ravens\n",
            "When you say you want to make a conscious decision that you want to make, how do you do this in the long term with your career, your music? Do you go beyond that and do it on a personal level?\n",
            "Chuck D\n",
            "I don’t do the solo thing as opposed to on a personal level. I like being very honest, if you guys, the one thing that happened all the way for the last three months wasn’t a decision. I’m not talking about a solo album thing. It happened for a year for me. I just like to keep that in mind. The thing is that I like to maintain a record that I want to put out, it’s my personal preference and it all comes to my personal preference and I don’t like to make something that just doesn’t work. So I think I could change one of my ideas and I can take a big risk and I can go off track and say, “I want this,” “Yeah, yeah, yeah.” I can make my own decisions, and I understand the concept there.\n",
            "It’s a little bit, I could go back to the ’90s. I’ll get into different situations because you just don’t really have to take that risk. I can see that there comes a time when you want to make a big thing, but no one’s necessarily in control. It’s just a thing that you do in your life.\n",
            "Chal Ravens\n",
            "You mentioned you don’t necessarily want to make a record by yourself. I think that’s one of your main focuses – and that’s something you have to think about when you’re making music too. Because it sounds too good, but…\n",
            "Chuck D\n",
            "You feel bad, but it’s not your personal thing. \n",
            "Chal Ravens\n",
            "What could go wrong if you decide to make a record by yourself? Because that’s just like your personal thing. It feels good to be honest.\n",
            "Chuck D\n",
            "Yeah because I know that’s why I’m a DJ, and I’m a DJ. I love the idea of just making music. I’m a DJ, like I love DJing. Not only that, but it takes you away from what it is you love to do. I think the more people who are still getting into the music – DJs, they’ve lost my passion for music. I don’t know if it made sense to do it all by yourself but I think that’s a good way to\n",
            "\n",
            "[810 | 3813.27] loss=2.82 avg=2.76\n",
            "[820 | 3859.44] loss=2.80 avg=2.76\n",
            "[830 | 3905.60] loss=2.70 avg=2.76\n",
            "[840 | 3951.78] loss=2.52 avg=2.75\n",
            "[850 | 3997.94] loss=2.68 avg=2.75\n",
            "[860 | 4044.06] loss=2.73 avg=2.75\n",
            "[870 | 4090.21] loss=2.63 avg=2.75\n",
            "[880 | 4136.27] loss=2.64 avg=2.75\n",
            "[890 | 4182.34] loss=2.70 avg=2.75\n",
            "[900 | 4228.47] loss=2.68 avg=2.75\n",
            "[910 | 4274.62] loss=2.73 avg=2.75\n",
            "[920 | 4320.80] loss=2.76 avg=2.75\n",
            "[930 | 4366.93] loss=2.82 avg=2.75\n",
            "[940 | 4413.06] loss=2.59 avg=2.75\n",
            "[950 | 4459.16] loss=2.60 avg=2.74\n",
            "[960 | 4505.37] loss=2.63 avg=2.74\n",
            "[970 | 4551.56] loss=2.61 avg=2.74\n",
            "[980 | 4597.72] loss=2.69 avg=2.74\n",
            "[990 | 4643.87] loss=2.65 avg=2.74\n",
            "[1000 | 4690.01] loss=2.78 avg=2.74\n",
            "Saving checkpoint/run1/model-1000\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/training/saver.py:963: remove_checkpoint (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IXSuTNERaw6K",
        "colab_type": "text"
      },
      "source": [
        "After the model is trained, you can copy the checkpoint folder to your own Google Drive.\n",
        "\n",
        "If you want to download it to your personal computer, it's strongly recommended you copy it there first, then download from Google Drive. The checkpoint folder is copied as a `.rar` compressed file; you can download it and uncompress it locally."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VHdTL8NDbAh3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_to_gdrive(run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qQJgV_b4bmzd",
        "colab_type": "text"
      },
      "source": [
        "You're done! Feel free to go to the **Generate Text From The Trained Model** section to generate text based on your retrained model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pel-uBULXO2L",
        "colab_type": "text"
      },
      "source": [
        "## Load a Trained Model Checkpoint\n",
        "\n",
        "Running the next cell will copy the `.rar` checkpoint file from your Google Drive into the Colaboratory VM."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DCcx5u7sbPTD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gpt2.copy_checkpoint_from_gdrive(run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTa6zf3e_9gV",
        "colab_type": "text"
      },
      "source": [
        "The next cell will allow you to load the retrained model checkpoint + metadata necessary to generate text.\n",
        "\n",
        "**IMPORTANT NOTE:** If you want to rerun this cell, **restart the VM first** (Runtime -> Restart Runtime). You will need to rerun imports but not recopy files."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-fxL77nvAMAX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "gpt2.load_gpt2(sess, run_name='run1')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClJwpF_ACONp",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Trained Model\n",
        "\n",
        "After you've trained the model or loaded a retrained model from checkpoint, you can now generate text. `generate` generates a single text from the loaded model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RNY6RBI9LmL",
        "colab_type": "code",
        "outputId": "a30d126a-13b0-47fa-953b-19f31bf1550a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 593
        }
      },
      "source": [
        "gpt2.generate(sess, run_name='run1')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "“I’m just wondering if you can tell us a little bit about the background of the original band that we were doing that you guys took on.”\n",
            "[laughter]\n",
            "I think it was Bobo [Howard] and Jazzy Jeff, and I don’t think we were even aware of the original band. I think it was a group called the Flamingos, and it was released on a label called A, which was the original A label, and we were also pressing records for a lot of the artists we were getting those requests for. We were also doing a lot of things on the side for the A label, and we were doing a lot of things on the side for the B label, which was the NME. It was a really big influence of what we were doing, and it was a really big inspiration for us, but it wasn’t who we were, it was who we were playing.\n",
            "I think we got a big kit, and then the band turned into a big influence. And I think it was the original A band, and we did a little bit of a remix on that, and we did the same thing with The Flamingos.\n",
            "I think we just put it out as a small label, and they were just like, “What would be a great idea to do that?” It was just as good as it could be. We just kind of stuck with it, and got a big kit, and we put it out as a small label, and we did a little remix on that, and we did a little bit of a remix on it, and we did a song on it, and did a whole lot of other stuff.\n",
            "It was just like, I don’t know, we had a little bit of a drinking problem in the first place, and we just wanted to make a little bit of money.\n",
            "We just kind of just started putting out records, and I think the whole thing with that is we just didn’t really want to be doing a big band. We just wanted to just do something that wasn’t really a big band. We just didn’t want to make a big band just because we just wanted to do something that was really a big band. We just just wanted to do something that wasn’t really a band.\n",
            "It was just like, I don’t know, there’s like a whole lot of these different bands that you can’t really say that they are all just a bunch of crazy, weird bands, but it is just like, “I want to do something that is really like a big band, and it has a good feel to it.” It is like, we just wanted to do something that was quite different from what people were expecting. We just wanted to do something that was obviously not the same as what people were expecting.\n",
            "Emma Warren\n",
            "I think it’s interesting to hear that you guys were able to get a lot of work out of doing the remixes for the original Flamingos. Was it like work was already done?\n",
            "Bobo Howard\n",
            "Yeah, I think it was done, but it works out very well. It was a really good idea to do the remixes for that band, we just didn’t want to do it one way or another.\n",
            "Emma Warren\n",
            "I think it was a great idea, but we also know that you guys did a little bit of flirting.\n",
            "Bobo Howard\n",
            "Yeah, we did a little bit of flirting, but we didn’t want to do anyone else. We just didn’t want to take anybody away from the band.\n",
            "Emma Warren\n",
            "It was actually a very different style of music, a lot of things, and you were just Iggy Pop and T.I. and the whole thing of, we’re not like, we just wanted to do something that was much more wholesome, and we didn’t want to be a band.\n",
            "Bobo Howard\n",
            "It was a really good way to do it.\n",
            "Emma Warren\n",
            "I think you guys have a lot of stories about it, but it’s hard to get a lot of the music off the internet.\n",
            "Bobo Howard\n",
            "It was really good. It was great.\n",
            "Emma Warren\n",
            "It’s very common for people to do that. I think it was also a good idea to get a few of those songs out, and it was a really good idea to do it in the studio.\n",
            "Bobo Howard\n",
            "We did a bunch of remixes for it, just in the studio, and it was a really great idea.\n",
            "Emma Warren\n",
            "It was a good idea to do it in the studio, too.\n",
            "Bobo Howard\n",
            "It was a great idea to do it in the studio, and we did quite a few things\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oF4-PqF0Fl7R",
        "colab_type": "text"
      },
      "source": [
        "If you're creating an API based on your model and need to pass the generated text elsewhere, you can do `text = gpt2.generate(sess, return_as_list=True)[0]`\n",
        "\n",
        "You can also pass in a `prefix` to the generate function to force the text to start with a given character sequence and generate text from there (good if you add an indicator when the text starts).\n",
        "\n",
        "You can also generate multiple texts at a time by specifing `nsamples`. Unique to GPT-2, you can pass a `batch_size` to generate multiple samples in parallel, giving a massive speedup (in Colaboratory, set a maximum of 20 for `batch_size`).\n",
        "\n",
        "Other optional-but-helpful parameters for `gpt2.generate` and friends:\n",
        "\n",
        "*  **`length`**: Number of tokens to generate (default 1023, the maximum)\n",
        "* **`temperature`**: The higher the temperature, the crazier the text (default 0.7, recommended to keep between 0.7 and 1.0)\n",
        "* **`top_k`**: Limits the generated guesses to the top *k* guesses (default 0 which disables the behavior; if the generated output is super crazy, you may want to set `top_k=40`)\n",
        "* **`top_p`**: Nucleus sampling: limits the generated guesses to a cumulative probability. (gets good results on a dataset with `top_p=0.9`)\n",
        "* **`truncate`**: Truncates the input text until a given sequence, excluding that sequence (e.g. if `truncate='<|endoftext|>'`, the returned text will include everything before the first `<|endoftext|>`). It may be useful to combine this with a smaller `length` if the input texts are short.\n",
        "*  **`include_prefix`**: If using `truncate` and `include_prefix=False`, the specified `prefix` will not be included in the returned text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8DKMc0fiej4N",
        "colab_type": "code",
        "outputId": "e9879f50-58c7-4856-ce9b-5038cb0c73f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              length=250,\n",
        "              temperature=0.7,\n",
        "              prefix=\"Ewen Henderson is here today.\",\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ewen Henderson is here today. We’re going to be talking about stories, stories. So at this point, what we want to have on our show is a story. We want to have some stories, yes? So we’re going to talk about stories and then we’ll just do a whole lot of music. So we’ll just start with a good story. So we’re going to start with a good story. So, we want to have a good story in this room.\n",
            "Torsten Schmidt    \n",
            "What are the elements in your telling that will make it interesting for listeners?\n",
            "Dixon    \n",
            "I don’t know. I don’t know. I think what we did was we did a song for a song, I think we did it for a song. And I remember when we did the song, I remember the first time we did it. And I remember I saw that. And I remember thinking, “Oh, that’s a good idea.” And I said, “Well, let’s just do something that we’re not doing yet.” And I said, “Well, I�\n",
            "====================\n",
            "Ewen Henderson is here today. I’m going to talk about some of the stuff that she did over the years. This stuff is amazing.\n",
            "(music: 9th Wonder –  “In My Mind” / applause)\n",
            "Jeff Mao\n",
            "How did you get these rhythms to come out of that?\n",
            "Gerald ‘Jazzman’ Short\n",
            "Well you’ll hear that I used to play drums. You’ll hear that I’m a drummer. You’ll hear that I’m an engineer. I’m a drummer, but I can’t really do anything with drums. I listen to some drummers and they do too much stuff. So when I started to play drums in high school, I started to listen to them. I found that I could really use that rhythm.\n",
            "Jeff Mao\n",
            "So that sounds like a bit of a high point for you.\n",
            "Gerald ‘Jazzman’ Short\n",
            "I think it’s a great example of a rhythm I can use on my own.\n",
            "Jeff Mao\n",
            "So we’re going to go to the next section.\n",
            "Buckshot\n",
            "Alright. So that’s the first one\n",
            "====================\n",
            "Ewen Henderson is here today. Welcome.\n",
            "(applause)\n",
            "AUDIENCE MEMBER\n",
            "Thank you.\n",
            "FRANKIE KNUCKLES\n",
            "Thank you.\n",
            "FRANKIE KNUCKLES\n",
            "Please, thank you.\n",
            "AUDIENCE MEMBER\n",
            "Thank you.\n",
            "FRANKIE KNUCKLES\n",
            "Which was exactly the question I had.\n",
            "AUDIENCE MEMBER\n",
            "Thank you.\n",
            "FRANKIE KNUCKLES\n",
            "Thank you.\n",
            "\n",
            "\n",
            "Lauren Martin isn’t afraid to go off the deep end. In her debut album, the self-taught singer and producer is dedicated to bringing dance music to the dancefloor, from her first single, “Thinking About Myself,” to her live performance in the 2012 Red Bull Music Academy. Martin also’s worked with her man, Robert Lydon, on the 2003 documentary “Black Cock.”\n",
            "In this lecture at the Red Bull Music Academy 2017 in New York City, she shares a piece of her music, her inspirations, and her thoughts on the music scene in the wake of the 2016 election.\n",
            "Lauren Martin\n",
            "So, for those who aren’t familiar with us, I’m going to play a song\n",
            "====================\n",
            "Ewen Henderson is here today.\n",
            "(music: The Mighty Turks – “Feed The Beast”)\n",
            "I want to give a huge shout out to the guys and gals in the room, the guys who have been making music with me since the beginning. They’ll be playing you something new, something fresh. And I want to give them a big shout out, because you know, I’m from New York, you know. So I want to give you a big shout out to the guys, the gals, who are doing their thing. I didn’t even have a studio so I had no room so I had to borrow my own equipment. So you get it.\n",
            "Benji B\n",
            "I thought I’d play something from your new album.\n",
            "(music: The Mighty Turks – “The Rapture” / applause)\n",
            "And I’m glad you asked and I guess that was when you said you were more interested in the sound of your music and the kind of groove that was laying in. I just wanted to ask you, how did you get into your own music and how did you get into it?\n",
            "Audience Member\n",
            "I was wondering how you got into it, because\n",
            "====================\n",
            "Ewen Henderson is here today.\n",
            "(applause)\n",
            "I’m pleased to introduce the guest of honor. I’m just going to play you an hour and a half of his first album, which really grabbed your attention. This is called The Art of the Steal. And as many of you know, I write things myself. It’s crazy. And I’m just really, really excited to present this. And it’s just going to be like, this is how I started writing. I’m from New Jersey and I started writing music in my parents’ basement. I think that was the first time I really was comfortable with writing music. I was just like, “OK, so, I’m going to try and get together and do some work.”\n",
            "I’m really, really excited about this, hearing this. I never really thought about the production process, I think it was just going to be a means to an end. I was just like, “I’m going to do this. I’m going to do this. I’ve got to write about it.” I was like, “OK, I�\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjEN2Tafhl2",
        "colab_type": "text"
      },
      "source": [
        "For bulk generation, you can generate a large amount of text to a file and sort out the samples locally on your computer. The next cell will generate a generated text file with a unique timestamp.\n",
        "\n",
        "You can rerun the cells as many times as you want for even more generated texts!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fa6p6arifSL0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gen_file = 'gpt2_gentext_{:%Y%m%d_%H%M%S}.txt'.format(datetime.utcnow())\n",
        "\n",
        "gpt2.generate_to_file(sess,\n",
        "                      destination_path=gen_file,\n",
        "                      temperature=0.7,\n",
        "                      nsamples=100,\n",
        "                      batch_size=20\n",
        "                      )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-LRex8lfv1g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# may have to run twice to get file to download\n",
        "files.download(gen_file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QQAN3M6RT7Kj",
        "colab_type": "text"
      },
      "source": [
        "## Generate Text From The Pretrained Model\n",
        "\n",
        "If you want to generate text from the pretrained model, not a finetuned model, pass `model_name` to `gpt2.load_gpt2()` and `gpt2.generate()`.\n",
        "\n",
        "This is currently the only way to generate text from the 774M \"large\" model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hsUd_jHgUZnD",
        "colab_type": "code",
        "outputId": "4e0c8a3f-3527-41c4-e3fe-3357f3f8f6c2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        }
      },
      "source": [
        "model_name = \"774M\"\n",
        "\n",
        "gpt2.download_gpt2(model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Fetching checkpoint: 1.05Mit [00:00, 354Mit/s]                                                      \n",
            "Fetching encoder.json: 1.05Mit [00:00, 131Mit/s]                                                    \n",
            "Fetching hparams.json: 1.05Mit [00:00, 279Mit/s]                                                    \n",
            "Fetching model.ckpt.data-00000-of-00001: 3.10Git [00:23, 131Mit/s]                                  \n",
            "Fetching model.ckpt.index: 1.05Mit [00:00, 380Mit/s]                                                \n",
            "Fetching model.ckpt.meta: 2.10Mit [00:00, 226Mit/s]                                                 \n",
            "Fetching vocab.bpe: 1.05Mit [00:00, 199Mit/s]                                                       \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAe4NpKNUj2C",
        "colab_type": "code",
        "outputId": "b09bfe1d-2ff8-4b8a-fffb-273d28d5d4ae",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "sess = gpt2.start_tf_sess()\n",
        "\n",
        "gpt2.load_gpt2(sess, model_name=model_name)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0828 18:37:58.571830 139905369159552 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to check for files with this prefix.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model models/774M/model.ckpt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-xInIZKaU104",
        "colab_type": "code",
        "outputId": "56348e28-7d08-45e3-c859-f26c0efd066d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        }
      },
      "source": [
        "gpt2.generate(sess,\n",
        "              model_name=model_name,\n",
        "              prefix=\"The secret of life is\",\n",
        "              length=100,\n",
        "              temperature=0.7,\n",
        "              top_p=0.9,\n",
        "              nsamples=5,\n",
        "              batch_size=5\n",
        "              )"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The secret of life is that it's really easy to make it complicated,\" said Bill Nye, the host of the popular science show \"Bill Nye the Science Guy.\" \"And this is one of the reasons why we all need to be smarter about science, because we can't keep up with the amazing things that are going on all the time.\"\n",
            "\n",
            "While Nye is correct that \"everything that's going on all the time\" is making the world a better place, he misses the point. This is not\n",
            "====================\n",
            "The secret of life is in the rhythm of the universe. It's not a mystery. It's not a mystery to me. It's the nature of the universe. It's the beauty of the universe. It's the way the universe works. It's the way the universe is. It's the way the universe is going to work. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way the universe is. It's the way\n",
            "====================\n",
            "The secret of life is in the universe.\n",
            "\n",
            "\n",
            "-\n",
            "\n",
            "The Red Devil\n",
            "\n",
            "It's the end of the world as we know it, and the only thing that can save us is a band of super-powered individuals known as the Red Devil.\n",
            "\n",
            "\n",
            "The Red Devil is a group of super-powered individuals who are seeking the secret of life and the only way they know how to do it is by taking on the roles of a variety of different super-powered individuals, each of which has their own\n",
            "====================\n",
            "The secret of life is in the mixing of the elements, and it is the mixing of the elements that makes life possible.\"\n",
            "\n",
            "But in the world of food science, the idea of a \"complex\" or \"complexity\" is almost entirely imaginary.\n",
            "\n",
            "As a scientist, I'm fascinated by the question of how life first began.\n",
            "\n",
            "It's the question that drives my work and the work of the scientists who work on it.\n",
            "\n",
            "My current research is exploring how microbes work in the first moments\n",
            "====================\n",
            "The secret of life is the journey of life, the search for the truth.\n",
            "\n",
            "4.4.2. The last thing you know\n",
            "\n",
            "There is nothing more important than the last thing you know.\n",
            "\n",
            "4.4.3. The little things that make all the difference\n",
            "\n",
            "The little things that make all the difference.\n",
            "\n",
            "4.4.4. The truth is the best teacher\n",
            "\n",
            "The truth is the best teacher.\n",
            "\n",
            "4.4.5. The truth is what\n",
            "====================\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ig-KVgkCDCKD",
        "colab_type": "text"
      },
      "source": [
        "# Etcetera\n",
        "\n",
        "If the notebook has errors (e.g. GPU Sync Fail), force-kill the Colaboratory virtual machine and restart it with the command below:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIHiVP53FnsX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kill -9 -1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmTXWNUygS5E",
        "colab_type": "text"
      },
      "source": [
        "# LICENSE\n",
        "\n",
        "MIT License\n",
        "\n",
        "Copyright (c) 2019 Max Woolf\n",
        "\n",
        "Permission is hereby granted, free of charge, to any person obtaining a copy\n",
        "of this software and associated documentation files (the \"Software\"), to deal\n",
        "in the Software without restriction, including without limitation the rights\n",
        "to use, copy, modify, merge, publish, distribute, sublicense, and/or sell\n",
        "copies of the Software, and to permit persons to whom the Software is\n",
        "furnished to do so, subject to the following conditions:\n",
        "\n",
        "The above copyright notice and this permission notice shall be included in all\n",
        "copies or substantial portions of the Software.\n",
        "\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\n",
        "IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\n",
        "FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\n",
        "AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\n",
        "LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\n",
        "OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE."
      ]
    }
  ]
}